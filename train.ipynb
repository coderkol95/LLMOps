{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "with open('input.txt','r') as f:\n",
    "    input=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "chars=sorted(list(set(input)))\n",
    "vocab_size=len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 47, 1, 58, 46, 43, 56, 43]\n",
      "Heyyy!\n"
     ]
    }
   ],
   "source": [
    "stoi = {ch:i for i,ch in enumerate(chars)}\n",
    "itos = {i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda s: ''.join([itos[i] for i in s])\n",
    "\n",
    "print(encode(\"Hi there\"))\n",
    "print(decode(encode(\"Heyyy!\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=torch.tensor(encode(input), dtype=torch.long)\n",
    "n=int(0.9*len(data))\n",
    "train_data=data[:n]\n",
    "val_data=data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18]) tensor(47)\n",
      "tensor([18, 47]) tensor(56)\n",
      "tensor([18, 47, 56]) tensor(57)\n",
      "tensor([18, 47, 56, 57]) tensor(58)\n",
      "tensor([18, 47, 56, 57, 58]) tensor(1)\n",
      "tensor([18, 47, 56, 57, 58,  1]) tensor(15)\n",
      "tensor([18, 47, 56, 57, 58,  1, 15]) tensor(47)\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47]) tensor(58)\n"
     ]
    }
   ],
   "source": [
    "block_size=8\n",
    "x=train_data[:block_size]\n",
    "y=train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context=x[:t+1]\n",
    "    target=y[t]\n",
    "    print(context,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "batch_size=4\n",
    "block_size=8\n",
    "\n",
    "def get_batch(split):\n",
    "    data=train_data if split==\"train\" else val_data\n",
    "    ix=torch.randint(len(data)-block_size,(batch_size,))\n",
    "    x=torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y=torch.stack([data[i+1:i+1+block_size] for i in ix])\n",
    "\n",
    "    return x,y\n",
    "\n",
    "xb,yb=get_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[57,  1, 46, 47, 57,  1, 50, 53],\n",
       "         [ 1, 58, 46, 43, 56, 43,  1, 41],\n",
       "         [17, 26, 15, 17, 10,  0, 32, 53],\n",
       "         [57, 58,  6,  1, 61, 47, 58, 46]]),\n",
       " tensor([[ 1, 46, 47, 57,  1, 50, 53, 60],\n",
       "         [58, 46, 43, 56, 43,  1, 41, 39],\n",
       "         [26, 15, 17, 10,  0, 32, 53,  1],\n",
       "         [58,  6,  1, 61, 47, 58, 46,  0]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb,yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim=65\n",
    "# Embedding dim has to be = vocab size as each alphabet is embedded in 1 dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self,vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table=nn.Embedding(vocab_size,embedding_dim)\n",
    "    def forward(self,idx,targets=None):\n",
    "        logits=self.token_embedding_table(idx)\n",
    "        if targets is None:\n",
    "            loss=None\n",
    "        else:\n",
    "            B,T,C=logits.shape # Batch size, timestamps, embedding size(channel size)\n",
    "            logits=logits.view(B*T,C)\n",
    "            targets=targets.view(B*T)\n",
    "            loss=F.cross_entropy(logits,targets)\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx,max_new_tokens):\n",
    "\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits,_=self(idx)\n",
    "            # Focus only on the last token.\n",
    "            logits=logits[:,-1,:]\n",
    "            # Apply softmax to get probs on the embedding dim\n",
    "            probs=F.softmax(logits,dim=-1)\n",
    "            # Sample from distribution of embeddings to generate the next token.\n",
    "            # This is what creates the randomness\n",
    "            idx_next=torch.multinomial(probs,num_samples=1)\n",
    "            # Append sampled index to the running sequence\n",
    "            idx=torch.cat((idx,idx_next),dim=1)\n",
    "        return idx\n",
    "    \n",
    "m=BigramLanguageModel(vocab_size)\n",
    "out,loss=m(xb,yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.4131, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k5/l531tc5j2070y5w0jlhbhfcw0000gn/T/ipykernel_14109/3220359612.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  decode(list(m.generate(torch.tensor(torch.zeros(1,1), dtype=torch.long),100).numpy()[0]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nh?',w;3cnImBqmJW'IcnsM,oRp:wXm;UsNz;jCtpIcEGpKyCAL-3?Y -EJleDjH;Kmzo$QTenDehAQy-GXJOJJj3wsvl&qCsLf3s\""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(list(m.generate(torch.tensor(torch.zeros(1,1), dtype=torch.long),100).numpy()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
